{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the device for GPU usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                      else  \"mps\" if torch.backends.mps.is_available()\n",
    "                      else \"cpu\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great cd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one of the best game music soundtracks   for a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batteries died within a year ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine, but maha energy is better</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great for the non audiophile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  polarity\n",
       "0                                           great cd         1\n",
       "1  one of the best game music soundtracks   for a...         1\n",
       "2                   batteries died within a year ...         0\n",
       "3              works fine, but maha energy is better         1\n",
       "4                       great for the non audiophile         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"../Datasets/Cleaned_Datasets/Dataset_1_test.csv\")\n",
    "new_df=df[[\"title\", \"polarity\"]].copy()\n",
    "new_df = new_df.head(10)\n",
    "new_df.polarity=new_df.polarity-1\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=512\n",
    "TRAIN_BATCH_SIZE=4\n",
    "VALID_BATCH_SIZE=4\n",
    "LEARNING_RATE=1e-05\n",
    "EPOCHS=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a BERT tokenizer from the 'bert-base-uncased' pre-trained model.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonTitles_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for tokenizing and encoding Amazon product titles\n",
    "    using a given tokenizer and preparing them for model training or inference.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas.DataFrame): The input DataFrame containing the titles and polarity labels.\n",
    "        tokenizer: The tokenizer object used to tokenize and encode the titles.\n",
    "        max_len (int): The maximum length of the tokenized titles after encoding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer=tokenizer\n",
    "        self.data=dataframe\n",
    "        self.titles=dataframe.title\n",
    "        self.targets=self.data.polarity\n",
    "        self.max_len=max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.titles)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        titles=str(self.titles[index])\n",
    "        titles = \" \".join(titles.split())\n",
    "    \n",
    "        inputs=self.tokenizer.encode_plus(\n",
    "            titles,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids=inputs['input_ids']\n",
    "        mask=inputs['attention_mask']\n",
    "        token_type_ids=inputs['token_type_ids'] \n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=0.8\n",
    "train_dataset=new_df.sample(frac=train_size, random_state=200)\n",
    "test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (10, 2)\n",
      "TRAIN Dataset: (8, 2)\n",
      "TEST Dataset: (2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = AmazonTitles_Dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = AmazonTitles_Dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClass(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(BertClass, self).__init__()\n",
    "        self.transformer = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.drop1 = torch.nn.BatchNorm1d(768)\n",
    "        self.l1 = torch.nn.Linear(768, 300)\n",
    "        self.act1=torch.nn.Tanh()\n",
    "        self.drop2 = torch.nn.Dropout(dropout)\n",
    "        self.l2 = torch.nn.Linear(300, 100)\n",
    "        self.act2=torch.nn.Tanh()\n",
    "        self.drop3=torch.nn.Dropout(dropout)\n",
    "        self.l3=torch.nn.Linear(100,1)\n",
    "        self.output=torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1=self.transformer(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
    "        output_2=self.drop1(output_1)\n",
    "        output_3=self.drop2(self.act1(self.l1(output_2)))\n",
    "        output_4=self.drop3(self.act2(self.l2(output_3)))\n",
    "        output=self.output(self.l3(output_4))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClass(\n",
       "  (transformer): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (drop1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (l1): Linear(in_features=768, out_features=300, bias=True)\n",
       "  (act1): Tanh()\n",
       "  (drop2): Dropout(p=0.1, inplace=False)\n",
       "  (l2): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (act2): Tanh()\n",
       "  (drop3): Dropout(p=0.1, inplace=False)\n",
       "  (l3): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=BertClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCELoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss=0.0\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "        targets = torch.unsqueeze(targets, dim=1)\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # Accumulate the total loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate the average loss for the epoch\n",
    "    avg_loss = total_loss / len(training_loader)\n",
    "\n",
    "    # Print the average loss for the epoch\n",
    "    print(f'Epoch: {epoch}, Average Loss: {avg_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Average Loss: 0.670420914888382\n",
      "Epoch: 1, Average Loss: 0.70011106133461\n",
      "Epoch: 2, Average Loss: 0.5975368618965149\n",
      "Epoch: 3, Average Loss: 0.6135385930538177\n",
      "Epoch: 4, Average Loss: 0.5756614208221436\n",
      "Epoch: 5, Average Loss: 0.6026521027088165\n",
      "Epoch: 6, Average Loss: 0.5976923108100891\n",
      "Epoch: 7, Average Loss: 0.5233611166477203\n",
      "Epoch: 8, Average Loss: 0.5083707869052887\n",
      "Epoch: 9, Average Loss: 0.5383757948875427\n",
      "Epoch: 10, Average Loss: 0.5032444000244141\n",
      "Epoch: 11, Average Loss: 0.4490460157394409\n",
      "Epoch: 12, Average Loss: 0.4447646737098694\n",
      "Epoch: 13, Average Loss: 0.47333845496177673\n",
      "Epoch: 14, Average Loss: 0.4543641358613968\n",
      "Epoch: 15, Average Loss: 0.4442123919725418\n",
      "Epoch: 16, Average Loss: 0.3866192549467087\n",
      "Epoch: 17, Average Loss: 0.4193197190761566\n",
      "Epoch: 18, Average Loss: 0.7582454085350037\n",
      "Epoch: 19, Average Loss: 0.3898744732141495\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            targets = torch.unsqueeze(targets, dim=1)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "Accuracy Score = 0.5\n",
      "F1 Score (Micro) = 0.5\n",
      "F1 Score (Macro) = 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
